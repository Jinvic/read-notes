#!/usr/bin/env python3
"""
å°†Hugoæ ¼å¼çš„ç¬”è®°è½¬æ¢ä¸ºMkDocsæ ¼å¼

ä¸»è¦è½¬æ¢ï¼š
1. æ‹†åˆ†ä¸€çº§æ ‡é¢˜ï¼ˆä¹¦åï¼‰ä¸ºç›®å½•
2. æ‹†åˆ†äºŒçº§æ ‡é¢˜ï¼ˆç« èŠ‚ï¼‰ä¸ºå•ç‹¬æ–‡ä»¶
3. è½¬æ¢Front Matteræ ¼å¼
4. æ›´æ–°å›¾ç‰‡é“¾æ¥è·¯å¾„
"""

import os
import sys
import json
import re
import logging
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import click
import frontmatter

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_metadata(src_md_file: Path) -> Optional[Dict]:
    """åŠ è½½ç¬”è®°çš„å…ƒæ•°æ®"""
    meta_file = src_md_file.parent / f"{src_md_file.name}.meta.json"
    if meta_file.exists():
        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            logger.warning(f"æ— æ³•è§£æå…ƒæ•°æ®æ–‡ä»¶ {meta_file}: {e}")
    return None

def sanitize_for_filename(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ï¼Œä½¿å…¶é€‚åˆä½œä¸ºæ–‡ä»¶å"""
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[ã€Šã€‹ã€ã€‘()ï¼ˆï¼‰<>:"/\\|?*]', '', text)
    # æ›¿æ¢ç©ºæ ¼å’Œæ ‡ç‚¹
    text = re.sub(r'[\s,ï¼Œã€‚\.ã€;ï¼›:ï¼š!ï¼?ï¼Ÿ]+', '-', text)
    # ç§»é™¤é¦–å°¾çš„è¿å­—ç¬¦
    text = text.strip('-')
    # é™åˆ¶é•¿åº¦
    if len(text) > 50:
        text = text[:50]
    return text.lower()

def extract_title_from_content(content: str) -> Tuple[str, str]:
    """ä»å†…å®¹ä¸­æå–æ ‡é¢˜
    
    è¿”å›: (title, remaining_content)
    """
    lines = content.split('\n')
    title = ""
    remaining_lines = []
    
    for line in lines:
        # æŸ¥æ‰¾ä¸€çº§æ ‡é¢˜ (Hugoé€šå¸¸æ˜¯ # æ ‡é¢˜)
        if line.startswith('# ') and not title:
            title = line[2:].strip()
            # ç»§ç»­å¤„ç†ï¼Œä¸æ·»åŠ åˆ°å‰©ä½™å†…å®¹
            continue
        # æŸ¥æ‰¾æ—§æ ¼å¼æ ‡é¢˜
        elif re.match(r'^#+\s+.+$', line) and not title:
            title = re.sub(r'^#+\s+', '', line).strip()
            continue
        else:
            remaining_lines.append(line)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not title:
        title = "æœªå‘½åç¬”è®°"
        logger.warning("æœªæ‰¾åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    return title, '\n'.join(remaining_lines)

def split_by_h2(content: str) -> List[Tuple[str, str]]:
    """æŒ‰äºŒçº§æ ‡é¢˜æ‹†åˆ†å†…å®¹
    
    è¿”å›: [(ç« èŠ‚æ ‡é¢˜, ç« èŠ‚å†…å®¹), ...]
    """
    sections = []
    
    # ä½¿ç”¨æ­£åˆ™åŒ¹é…äºŒçº§æ ‡é¢˜
    pattern = r'(^##\s+.+?$)(?=\n##\s+|\Z)'
    
    # ä½¿ç”¨å¤šè¡Œæ¨¡å¼
    matches = list(re.finditer(pattern, content, re.MULTILINE | re.DOTALL))
    
    if not matches:
        # å¦‚æœæ²¡æœ‰äºŒçº§æ ‡é¢˜ï¼Œæ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªç« èŠ‚
        sections.append(("æ¦‚è¿°", content))
        return sections
    
    for i, match in enumerate(matches):
        section_content = match.group(0)
        
        # æå–æ ‡é¢˜
        lines = section_content.split('\n')
        if lines and lines[0].startswith('## '):
            section_title = lines[0][3:].strip()
            # ç§»é™¤æ ‡é¢˜è¡Œï¼Œä¿ç•™å†…å®¹
            section_body = '\n'.join(lines[1:]).strip()
        else:
            section_title = f"ç« èŠ‚-{i+1}"
            section_body = section_content
        
        sections.append((section_title, section_body))
    
    return sections

def convert_image_links(content: str, note_clean_name: str, image_base: str) -> str:
    """è½¬æ¢å›¾ç‰‡é“¾æ¥è·¯å¾„
    
    å°†Hugoæ ¼å¼çš„å›¾ç‰‡é“¾æ¥è½¬æ¢ä¸ºMkDocsæ ¼å¼
    """
    # å¤„ç†Hugoæ ¼å¼çš„å›¾ç‰‡é“¾æ¥: ![alt](/post-images/ç¬”è®°å/xxx.png)
    # è½¬æ¢ä¸º: ![alt](/assets/images/clean-note-name/xxx.png)
    
    # é¦–å…ˆå¤„ç†æ ‡å‡†æ ¼å¼
    pattern1 = r'!\[(.*?)\]\(\s*/post-images/[^/]+/([^)\s]+)\s*\)'
    replacement1 = rf'![\1]({image_base}/{note_clean_name}/\2)'
    content = re.sub(pattern1, replacement1, content, flags=re.IGNORECASE)
    
    # å¤„ç†å¯èƒ½çš„ä¸åŒæ ¼å¼
    pattern2 = r'!\[(.*?)\]\(\s*(\.\./)*static/post-images/[^/]+/([^)\s]+)\s*\)'
    replacement2 = rf'![\1]({image_base}/{note_clean_name}/\3)'
    content = re.sub(pattern2, replacement2, content, flags=re.IGNORECASE)
    
    # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚æœå›¾ç‰‡åœ¨src/imagesç›®å½•ï¼‰
    pattern3 = r'!\[(.*?)\]\(\s*\.?/?images/[^/]+/([^)\s]+)\s*\)'
    replacement3 = rf'![\1]({image_base}/{note_clean_name}/\2)'
    content = re.sub(pattern3, replacement3, content, flags=re.IGNORECASE)
    
    return content

def create_mkdocs_frontmatter(title: str, original_frontmatter: Dict = None) -> str:
    """åˆ›å»ºMkDocsæ ¼å¼çš„Front Matter"""
    frontmatter_lines = ["---"]
    
    # æ·»åŠ æ ‡é¢˜
    frontmatter_lines.append(f"title: {title}")
    
    # ä¿ç•™ä¸€äº›æœ‰ç”¨çš„åŸæ•°æ®
    if original_frontmatter:
        # ä¿ç•™æ—¥æœŸï¼ˆå¦‚æœæœ‰ï¼‰
        if 'date' in original_frontmatter:
            frontmatter_lines.append(f"date: {original_frontmatter['date']}")
        
        # ä¿ç•™æ ‡ç­¾ï¼ˆè½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼‰
        if 'tags' in original_frontmatter:
            tags = original_frontmatter['tags']
            if isinstance(tags, list):
                frontmatter_lines.append(f"tags: {tags}")
            else:
                frontmatter_lines.append(f"tags: [{tags}]")
    
    # æ·»åŠ ä¸€äº›é»˜è®¤å€¼
    frontmatter_lines.append("template: article.html")
    frontmatter_lines.append("---\n")
    
    return '\n'.join(frontmatter_lines)

def convert_single_note(src_md_file: Path, output_base_dir: Path, 
                       note_clean_name: str, image_base: str) -> int:
    """è½¬æ¢å•ç¯‡ç¬”è®°ï¼Œè¿”å›ç”Ÿæˆçš„ç« èŠ‚æ•°"""
    
    # åŠ è½½å…ƒæ•°æ®
    metadata = load_metadata(src_md_file)
    
    # è¯»å–Markdownæ–‡ä»¶
    try:
        with open(src_md_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        # å°è¯•å…¶ä»–ç¼–ç 
        with open(src_md_file, 'r', encoding='gbk') as f:
            content = f.read()
    
    # è§£æFront Matterï¼ˆå¦‚æœæœ‰ï¼‰
    original_frontmatter = {}
    try:
        post = frontmatter.loads(content)
        content_without_fm = post.content
        original_frontmatter = post.metadata
    except:
        content_without_fm = content
        logger.warning(f"æ— æ³•è§£æFront Matter: {src_md_file.name}")
    
    # æå–æ ‡é¢˜
    title, remaining_content = extract_title_from_content(content_without_fm)
    
    # å¦‚æœæ²¡æœ‰ä»å†…å®¹ä¸­æ‰¾åˆ°æ ‡é¢˜ï¼Œå°è¯•ä»Front Matterè·å–
    if title == "æœªå‘½åç¬”è®°" and 'title' in original_frontmatter:
        title = original_frontmatter['title']
    
    # è½¬æ¢å›¾ç‰‡é“¾æ¥
    content_converted = convert_image_links(remaining_content, note_clean_name, image_base)
    
    # æŒ‰äºŒçº§æ ‡é¢˜æ‹†åˆ†å†…å®¹
    sections = split_by_h2(content_converted)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = output_base_dir / note_clean_name
    output_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"ğŸ“– è½¬æ¢: {src_md_file.name} -> {note_clean_name}/ ({len(sections)}ä¸ªç« èŠ‚)")
    
    # ç”Ÿæˆç´¢å¼•æ–‡ä»¶ï¼ˆç¬¬ä¸€ä¸ªç« èŠ‚æˆ–æ¦‚è¿°ï¼‰
    if sections:
        first_section_title, first_section_content = sections[0]
        
        # åˆ›å»ºç´¢å¼•æ–‡ä»¶
        index_content = create_mkdocs_frontmatter(title, original_frontmatter)
        index_content += f"# {title}\n\n"
        
        # ç”Ÿæˆç›®å½•
        if len(sections) > 1:
            index_content += "## ç›®å½•\n\n"
            for i, (section_title, _) in enumerate(sections):
                section_filename = f"chapter-{i+1:02d}.md" if i > 0 else "index.md"
                index_content += f"{i+1}. [{section_title}]({section_filename})\n"
            index_content += "\n"
        
        # æ·»åŠ ç¬¬ä¸€ä¸ªç« èŠ‚çš„å†…å®¹
        index_content += first_section_content
        
        # å†™å…¥ç´¢å¼•æ–‡ä»¶
        index_file = output_dir / "index.md"
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(index_content)
        
        # ç”Ÿæˆå…¶ä»–ç« èŠ‚æ–‡ä»¶
        for i, (section_title, section_content) in enumerate(sections[1:], 1):
            chapter_filename = f"chapter-{i+1:02d}.md"
            chapter_file = output_dir / chapter_filename
            
            # ç« èŠ‚çš„Front Matter
            chapter_fm = create_mkdocs_frontmatter(f"{title} - {section_title}", original_frontmatter)
            
            # ç« èŠ‚å†…å®¹
            chapter_content = f"{chapter_fm}# {section_title}\n\n{section_content}\n"
            
            # æ·»åŠ è¿”å›ç´¢å¼•çš„é“¾æ¥
            chapter_content += f"\n\n---\n\nâ† [è¿”å›ç›®å½•](index.md)"
            
            with open(chapter_file, 'w', encoding='utf-8') as f:
                f.write(chapter_content)
        
        logger.info(f"  âœ… ç”Ÿæˆ {len(sections)} ä¸ªæ–‡ä»¶åˆ° {note_clean_name}/")
    
    return len(sections)

@click.command()
@click.option('--src-dir', default='./src', help='æºæ–‡ä»¶ç›®å½•ï¼ˆHugoæ ¼å¼ï¼‰')
@click.option('--output-dir', default='./docs/reading-notes', help='è¾“å‡ºç›®å½•ï¼ˆMkDocsæ ¼å¼ï¼‰')
@click.option('--image-base', default='/assets/images', help='å›¾ç‰‡åŸºç¡€è·¯å¾„')
@click.option('--log-level', default='INFO', help='æ—¥å¿—çº§åˆ«')
def main(src_dir: str, output_dir: str, image_base: str, log_level: str):
    """ä¸»å‡½æ•°ï¼šè½¬æ¢Hugoç¬”è®°ä¸ºMkDocsæ ¼å¼"""
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # è½¬æ¢è·¯å¾„
    src_dir_path = Path(src_dir).resolve()
    output_dir_path = Path(output_dir).resolve()
    
    # éªŒè¯æºç›®å½•
    if not src_dir_path.exists():
        logger.error(f"æºç›®å½•ä¸å­˜åœ¨: {src_dir_path}")
        sys.exit(1)
    
    # æ¸…ç†è¾“å‡ºç›®å½•
    if output_dir_path.exists():
        logger.info(f"æ¸…ç†æ—§çš„è¾“å‡ºç›®å½•: {output_dir_path}")
        shutil.rmtree(output_dir_path)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir_path.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(src_dir_path.glob("*.md"))
    if not md_files:
        logger.error(f"æœªæ‰¾åˆ°Markdownæ–‡ä»¶: {src_dir_path}")
        sys.exit(1)
    
    logger.info(f"ğŸ“‹ å¼€å§‹è½¬æ¢ {len(md_files)} ç¯‡ç¬”è®°")
    
    total_sections = 0
    success_count = 0
    
    for md_file in md_files:
        logger.info(f"--- å¤„ç†: {md_file.name} ---")
        
        try:
            # è·å–ç¬”è®°çš„clean name
            metadata = load_metadata(md_file)
            if metadata and 'clean_name' in metadata:
                note_clean_name = metadata['clean_name']
            elif metadata and 'target_dir' in metadata:
                note_clean_name = metadata['target_dir']
            else:
                # ä»æ–‡ä»¶åç”Ÿæˆclean name
                note_name = md_file.stem
                note_clean_name = sanitize_for_filename(note_name)
            
            # è½¬æ¢å•ç¯‡ç¬”è®°
            sections_count = convert_single_note(
                md_file, output_dir_path, note_clean_name, image_base
            )
            
            total_sections += sections_count
            success_count += 1
            
            logger.info(f"âœ… å®Œæˆ: {md_file.name} -> {note_clean_name}/ ({sections_count}ç« èŠ‚)")
            
        except Exception as e:
            logger.error(f"âŒ è½¬æ¢å¤±è´¥ {md_file.name}: {e}")
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    logger.info(f"ğŸ‰ è½¬æ¢å®Œæˆæ€»ç»“")
    logger.info(f"   æˆåŠŸè½¬æ¢: {success_count}/{len(md_files)} ç¯‡ç¬”è®°")
    logger.info(f"   ç”Ÿæˆç« èŠ‚: {total_sections} ä¸ª")
    logger.info(f"   è¾“å‡ºç›®å½•: {output_dir_path}")
    
    # æ˜¾ç¤ºç”Ÿæˆçš„ç›®å½•ç»“æ„
    logger.info(f"ğŸ“‚ ç”Ÿæˆçš„ç›®å½•ç»“æ„:")
    for item in output_dir_path.iterdir():
        if item.is_dir():
            md_files_in_dir = list(item.glob("*.md"))
            logger.info(f"  ğŸ“ {item.name}/ ({len(md_files_in_dir)}ä¸ªæ–‡ä»¶)")
            for md in md_files_in_dir[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶
                logger.info(f"    ğŸ“„ {md.name}")
            if len(md_files_in_dir) > 3:
                logger.info(f"    ... è¿˜æœ‰ {len(md_files_in_dir)-3} ä¸ªæ–‡ä»¶")
    
    if success_count < len(md_files):
        logger.warning(f"âš ï¸  æœ‰ {len(md_files) - success_count} ç¯‡ç¬”è®°è½¬æ¢å¤±è´¥")
        sys.exit(1)

if __name__ == '__main__':
    main()